{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from configobj import ConfigObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigObj(infile='twt_cfg.ini') # twitter app api config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = config['consumerkey']\n",
    "CONSUMER_SECRET = config['consumersecret']\n",
    "ACCESS_TOKEN  = config['accesstoken']\n",
    "ACCESS_SECRET = config['accesssecret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    alltweets = []\n",
    "    \n",
    "    new_tweets = api.user_timeline(screen_name = screen_name, count=200)\n",
    "\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "    \n",
    "    data = pd.DataFrame(columns=['id','text','favorites','retweets'])\n",
    "    row_index = 0\n",
    "    \n",
    "    for tweet in alltweets:\n",
    "        if not tweet.entities['user_mentions']: # makes sure its not a reply to any tweets\n",
    "            \n",
    "            data.loc[row_index, ['id']] = tweet.id_str\n",
    "            data.loc[row_index, ['text']] = tweet.text\n",
    "            data.loc[row_index, ['favorites']] = tweet.favorite_count\n",
    "            data.loc[row_index, ['retweets']] = tweet.retweet_count\n",
    "            row_index += 1\n",
    "\n",
    "    data.to_csv('{}_tweets.csv'.format(screen_name), index=False)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1028982012374208512\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1022328682034081791\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 1012934540375908351\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 1005050495952547840\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 996655012913663999\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 989078099777245183\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 981094137662287871\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 971690342750670849\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 962978188228935679\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 953924926016114688\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 945243964742934527\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 935395280719044607\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 924955706272358404\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 913017884556906495\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 902140136967651327\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 889321262706642944\n",
      "...3213 tweets downloaded so far\n",
      "getting tweets before 887994413535772671\n",
      "...3213 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"MyIndusIndBank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MyIndusIndBank_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
